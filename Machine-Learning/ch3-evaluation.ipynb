{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch.3 - 평가(Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit( ) 메소드는 아무것도 학습하지 않음. \n",
    "    def fit(self , X , y=None):\n",
    "            pass\n",
    "    \n",
    "    # predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함. \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( ( X.shape[0] , 1))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null 처리 함수\n",
    "\n",
    "def fillna(df) :\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. \n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train ,y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self,X):\n",
    "        return np.zeros( (len(X),1) , dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True로 이를 astype(int)로 1로 변환, 7번이 아니면 False고 0으로 변환. \n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train , y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞절의 예측 결과인 fakepred와 실제 결과인 y_test의 Confusion Matrix출력\n",
    "confusion_matrix(y_test , fakepred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "skm.confusion_matrix(y_test , fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도(Precision)와 재현율(Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred) :\n",
    "    confusion = confusion_matrix( y_test, pred)  # confusion_matrix  오차 행렬\n",
    "    accuracy = accuracy_score(y_test , pred)     # accuracy_score    정확도\n",
    "    precision = precision_score(y_test , pred)   # precision_score   정밀도\n",
    "    recall = recall_score(y_test , pred)         # recall_score      재현율\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할.\n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)\n",
    "\n",
    "# 정확도는 전체분에 TN + TP ,\n",
    "# 재현율은 전체의 실제있는 값(FN+TP)분에 TP,\n",
    "# 정말도는 있다고 예측한 전체(FP+TP)분에 TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4616653 , 0.5383347 ],\n",
       "       [0.87862763, 0.12137237],\n",
       "       [0.87727002, 0.12272998],\n",
       "       [0.88283621, 0.11716379],\n",
       "       [0.85508952, 0.14491048],\n",
       "       [0.88231157, 0.11768843],\n",
       "       [0.88838988, 0.11161012],\n",
       "       [0.20916926, 0.79083074],\n",
       "       [0.78258628, 0.21741372],\n",
       "       [0.36993909, 0.63006091],\n",
       "       [0.89988359, 0.10011641],\n",
       "       [0.87482056, 0.12517944],\n",
       "       [0.87726414, 0.12273586],\n",
       "       [0.88834471, 0.11165529],\n",
       "       [0.43495818, 0.56504182],\n",
       "       [0.85888537, 0.14111463],\n",
       "       [0.9037587 , 0.0962413 ],\n",
       "       [0.73319742, 0.26680258],\n",
       "       [0.72417011, 0.27582989],\n",
       "       [0.17255821, 0.82744179],\n",
       "       [0.75341614, 0.24658386],\n",
       "       [0.61951539, 0.38048461],\n",
       "       [0.85451436, 0.14548564],\n",
       "       [0.81519357, 0.18480643],\n",
       "       [0.88797994, 0.11202006],\n",
       "       [0.76533031, 0.23466969],\n",
       "       [0.85969194, 0.14030806],\n",
       "       [0.92608161, 0.07391839],\n",
       "       [0.71933832, 0.28066168],\n",
       "       [0.69482833, 0.30517167],\n",
       "       [0.05265215, 0.94734785],\n",
       "       [0.18218452, 0.81781548],\n",
       "       [0.87342764, 0.12657236],\n",
       "       [0.17444334, 0.82555666],\n",
       "       [0.60039903, 0.39960097],\n",
       "       [0.76533031, 0.23466969],\n",
       "       [0.92770628, 0.07229372],\n",
       "       [0.38856768, 0.61143232],\n",
       "       [0.94700636, 0.05299364],\n",
       "       [0.89606698, 0.10393302],\n",
       "       [0.64979315, 0.35020685],\n",
       "       [0.91687904, 0.08312096],\n",
       "       [0.17785026, 0.82214974],\n",
       "       [0.29217043, 0.70782957],\n",
       "       [0.36972173, 0.63027827],\n",
       "       [0.36970571, 0.63029429],\n",
       "       [0.08134084, 0.91865916],\n",
       "       [0.64356261, 0.35643739],\n",
       "       [0.05107107, 0.94892893],\n",
       "       [0.88794595, 0.11205405],\n",
       "       [0.40552739, 0.59447261],\n",
       "       [0.88834471, 0.11165529],\n",
       "       [0.86713139, 0.13286861],\n",
       "       [0.2752142 , 0.7247858 ],\n",
       "       [0.69034518, 0.30965482],\n",
       "       [0.80336908, 0.19663092],\n",
       "       [0.77339578, 0.22660422],\n",
       "       [0.87726899, 0.12273101],\n",
       "       [0.84567023, 0.15432977],\n",
       "       [0.567331  , 0.432669  ],\n",
       "       [0.7196256 , 0.2803744 ],\n",
       "       [0.89912834, 0.10087166],\n",
       "       [0.4531912 , 0.5468088 ],\n",
       "       [0.48659488, 0.51340512],\n",
       "       [0.55525453, 0.44474547],\n",
       "       [0.90540205, 0.09459795],\n",
       "       [0.33300938, 0.66699062],\n",
       "       [0.405798  , 0.594202  ],\n",
       "       [0.04802869, 0.95197131],\n",
       "       [0.85227085, 0.14772915],\n",
       "       [0.87091694, 0.12908306],\n",
       "       [0.83139387, 0.16860613],\n",
       "       [0.89606477, 0.10393523],\n",
       "       [0.05210655, 0.94789345],\n",
       "       [0.80129197, 0.19870803],\n",
       "       [0.88834471, 0.11165529],\n",
       "       [0.65119863, 0.34880137],\n",
       "       [0.81631432, 0.18368568],\n",
       "       [0.1641845 , 0.8358155 ],\n",
       "       [0.87726899, 0.12273101],\n",
       "       [0.20478201, 0.79521799],\n",
       "       [0.35636331, 0.64363669],\n",
       "       [0.06916504, 0.93083496],\n",
       "       [0.86679209, 0.13320791],\n",
       "       [0.05082798, 0.94917202],\n",
       "       [0.04927439, 0.95072561],\n",
       "       [0.84692967, 0.15307033],\n",
       "       [0.87462061, 0.12537939],\n",
       "       [0.12576591, 0.87423409],\n",
       "       [0.88834471, 0.11165529],\n",
       "       [0.88834471, 0.11165529],\n",
       "       [0.76533031, 0.23466969],\n",
       "       [0.76796732, 0.23203268],\n",
       "       [0.88834471, 0.11165529],\n",
       "       [0.36970571, 0.63029429],\n",
       "       [0.92431193, 0.07568807],\n",
       "       [0.07114316, 0.92885684],\n",
       "       [0.89927326, 0.10072674],\n",
       "       [0.49284253, 0.50715747],\n",
       "       [0.03482499, 0.96517501],\n",
       "       [0.49887769, 0.50112231],\n",
       "       [0.90528473, 0.09471527],\n",
       "       [0.05182599, 0.94817401],\n",
       "       [0.90245157, 0.09754843],\n",
       "       [0.47024934, 0.52975066],\n",
       "       [0.8715469 , 0.1284531 ],\n",
       "       [0.85883907, 0.14116093],\n",
       "       [0.85227115, 0.14772885],\n",
       "       [0.55063838, 0.44936162],\n",
       "       [0.89264243, 0.10735757],\n",
       "       [0.88301917, 0.11698083],\n",
       "       [0.89108421, 0.10891579],\n",
       "       [0.5961089 , 0.4038911 ],\n",
       "       [0.34562047, 0.65437953],\n",
       "       [0.88797994, 0.11202006],\n",
       "       [0.92886443, 0.07113557],\n",
       "       [0.87568437, 0.12431563],\n",
       "       [0.80151851, 0.19848149],\n",
       "       [0.07408816, 0.92591184],\n",
       "       [0.93137314, 0.06862686],\n",
       "       [0.88835342, 0.11164658],\n",
       "       [0.86952314, 0.13047686],\n",
       "       [0.93652783, 0.06347217],\n",
       "       [0.6796694 , 0.3203306 ],\n",
       "       [0.98837423, 0.01162577],\n",
       "       [0.88835342, 0.11164658],\n",
       "       [0.8838315 , 0.1161685 ],\n",
       "       [0.68302867, 0.31697133],\n",
       "       [0.32252619, 0.67747381],\n",
       "       [0.67816184, 0.32183816],\n",
       "       [0.03482499, 0.96517501],\n",
       "       [0.54534337, 0.45465663],\n",
       "       [0.26501474, 0.73498526],\n",
       "       [0.56030935, 0.43969065],\n",
       "       [0.42981665, 0.57018335],\n",
       "       [0.65153352, 0.34846648],\n",
       "       [0.25188893, 0.74811107],\n",
       "       [0.81350687, 0.18649313],\n",
       "       [0.89604002, 0.10395998],\n",
       "       [0.1970313 , 0.8029687 ],\n",
       "       [0.09102184, 0.90897816],\n",
       "       [0.85227115, 0.14772885],\n",
       "       [0.88206895, 0.11793105],\n",
       "       [0.89881602, 0.10118398],\n",
       "       [0.90837231, 0.09162769],\n",
       "       [0.33300139, 0.66699861],\n",
       "       [0.92435623, 0.07564377],\n",
       "       [0.76629675, 0.23370325],\n",
       "       [0.08143357, 0.91856643],\n",
       "       [0.83165574, 0.16834426],\n",
       "       [0.57095053, 0.42904947],\n",
       "       [0.36919657, 0.63080343],\n",
       "       [0.36297759, 0.63702241],\n",
       "       [0.87732364, 0.12267636],\n",
       "       [0.22194663, 0.77805337],\n",
       "       [0.11902243, 0.88097757],\n",
       "       [0.51114472, 0.48885528],\n",
       "       [0.86697059, 0.13302941],\n",
       "       [0.24901149, 0.75098851],\n",
       "       [0.30962207, 0.69037793],\n",
       "       [0.85010991, 0.14989009],\n",
       "       [0.20757902, 0.79242098],\n",
       "       [0.90872691, 0.09127309],\n",
       "       [0.33307577, 0.66692423],\n",
       "       [0.61972611, 0.38027389],\n",
       "       [0.34853313, 0.65146687],\n",
       "       [0.11605976, 0.88394024],\n",
       "       [0.69083685, 0.30916315],\n",
       "       [0.90835336, 0.09164664],\n",
       "       [0.10658416, 0.89341584],\n",
       "       [0.88838988, 0.11161012],\n",
       "       [0.14536833, 0.85463167],\n",
       "       [0.74976957, 0.25023043],\n",
       "       [0.75943956, 0.24056044],\n",
       "       [0.60190851, 0.39809149],\n",
       "       [0.93773464, 0.06226536],\n",
       "       [0.85883217, 0.14116783],\n",
       "       [0.45374857, 0.54625143],\n",
       "       [0.37240425, 0.62759575]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred_proba     # proba는 확률을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred                   # predict는 확률의 0.5를 기준으로 값을 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[ 1, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]\n",
    "\n",
    "# 리스트 X에 대하여 입력한 threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold = 1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값. 분류 결정 임곗값임.\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환값의 두번째컬럼, 즉 Positive 클래스컬럼 하나만 추출해 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold)\n",
    "custom_predict = binarizer.fit_transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정.\n",
    "custom_threshold = 0.4\n",
    "\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold)\n",
    "custom_predict = binarizer.fit_transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)             # 숫자가 조금씩 틀릴 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361, F1:0.7786\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033, F1:0.7840\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541, F1:0.7931\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377, F1:0.8036\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361, F1:0.7786\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033, F1:0.7840\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541, F1:0.7931\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377, F1:0.8036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_clf_eval(y_test, pred) :\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    \n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    \n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "        \n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index 10개: [ 1  6 11 16 21 26 31 36 41 46 51]\n",
      "샘플용 10개의 임곗값:  [0.97 0.65 0.63 0.57 0.45 0.38 0.31 0.13 0.12 0.11 0.1 ]\n",
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.076 0.127 0.186 0.237 0.576 0.619 0.754 0.814]\n",
      "샘플 임곗값별 TPR:  [0.033 0.639 0.705 0.754 0.803 0.852 0.902 0.902 0.951 0.967 1.   ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일 때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출.\n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def roc_curve_plot(y_test, pred_proba_c1) :\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환받음.\n",
    "    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "    # ROC 곡선을 그래프 곡선으로 그림.\n",
    "    plt.plot(fprs, tprs, label='ROC')\n",
    "    # 가운데 대각선 직선을 그림.\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label = 'Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X, Y축 명 설정 등\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 값: 0.9024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 피마 인디언 당뇨병 사례\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "print(diabetes_data['Outcome'].value_counts())\n",
    "diabetes_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 데이터 세트 X, 레이블 데이터 세트 y를 추출.\n",
    "# 맨 끝이 Outcome 칼럼으로 레이블 값임. 칼럼 위치 -1을 이용해 추출\n",
    "X = diabetes_data.iloc[:, :-1]\n",
    "y = diabetes_data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split\\\n",
    "(X, y, test_size = 0.2, random_state = 156, stratify = y)\n",
    "\n",
    "# 로지스틱 회귀로 학습, 예측 및 평가 수행.\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
